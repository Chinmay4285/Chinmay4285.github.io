<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects - Chinmay Yalameli</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="experience.html">Experience</a></li>
            <li><a href="projects.html" class="active">Projects</a></li>
            <li><a href="about.html">About</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>

    <main>
        <h1>Projects</h1>
        <p>Personal projects exploring ML system design, model evaluation, and production tradeoffs. All open source.</p>

        <!-- Project 1: Transformer Recommendation Engine -->
        <div class="project">
            <span class="project-label">Personal</span>
            <h3>Transformer-Based Recommendation Engine</h3>
            <p>Sequential recommendation system using transformer encoder architecture. Trained on 2.7M real e-commerce events (Retailrocket dataset) with proper temporal splits to prevent data leakage.</p>

            <p><strong>Technical approach:</strong> Implemented positional encoding for sequential modeling, built evaluation framework with HR, NDCG, Recall, and MRR metrics, compared against popularity and item-kNN baselines. Achieved NDCG@10 of 0.08-0.15 with 10-25% improvement over baselines.</p>

            <p><strong>Key decision:</strong> Chose transformer encoder over RNN/LSTM to better capture long-range dependencies in session data. Tradeoff: higher training cost for improved recommendation quality at inference.</p>

            <div class="tech-stack">
                <strong>Tech Stack:</strong>
                <span>PyTorch, pandas, scikit-learn</span>
            </div>

            <p><a href="https://github.com/Chinmay4285/transformer_recommendation_engine" target="_blank">View on GitHub →</a></p>
        </div>

        <!-- Project 2: Skin Cancer Classification -->
        <div class="project">
            <span class="project-label">Research</span>
            <h3>Interpretable ML for Healthcare - Two-Tier System</h3>
            <p>Case study in building interpretable ML for clinical deployment. Problem: Healthcare models need both high accuracy and explainable predictions for practitioner trust and regulatory approval.</p>

            <p><strong>Technical approach:</strong> Implemented two-tier architecture—Tier 1: ensemble (logistic regression + XGBoost + RNN/LSTM) for accuracy; Tier 2: interpretability layer with SHAP analysis and clinical decision rules. Engineered 35 features from ABCDE melanoma detection criteria. Used synthetic data (1,200 records) to avoid privacy issues.</p>

            <p><strong>Key decision:</strong> Prioritized interpretability alongside accuracy rather than optimizing for accuracy alone. Ensemble achieved 78.3% accuracy while maintaining explainable predictions via logistic regression coefficients and feature importance.</p>

            <div class="tech-stack">
                <strong>Tech Stack:</strong>
                <span>scikit-learn, XGBoost, TensorFlow, SHAP</span>
            </div>

            <p><a href="https://github.com/Chinmay4285/skin-cancer-classification" target="_blank">View on GitHub →</a></p>
        </div>

        <!-- Project 3: LSTM Sentiment Analysis -->
        <div class="project">
            <span class="project-label">Personal</span>
            <h3>Production Sentiment Analysis with Flask API</h3>
            <p>Bidirectional LSTM for text classification deployed as Flask web service. Explored sequence modeling tradeoffs for sentiment analysis.</p>

            <p><strong>Technical approach:</strong> Two-layer bidirectional LSTM with dropout regularization (0.3, 0.5) and 128-dim word embeddings. Built preprocessing pipeline handling tokenization, sequence padding, and batch predictions. Deployed as REST API with single and batch endpoints.</p>

            <p><strong>Results:</strong> 91.2% accuracy on balanced dataset, macro F1 of 90.6%. ~100 texts/second inference on GPU. Model handles positive, negative, neutral sentiment with confidence scoring.</p>

            <div class="tech-stack">
                <strong>Tech Stack:</strong>
                <span>TensorFlow/Keras, Flask, NLTK</span>
            </div>

            <p><a href="https://github.com/Chinmay4285/lstm-sentiment" target="_blank">View on GitHub →</a></p>
        </div>

        <!-- Project 4: Classification Algorithms Comparison -->
        <div class="project">
            <span class="project-label">Personal</span>
            <h3>ML Algorithm Performance Comparison</h3>
            <p>Systematic implementation and evaluation of 10 classification algorithms to understand performance characteristics across different model families.</p>

            <p><strong>Scope:</strong> Implemented logistic regression, naive bayes, KNN, decision trees, random forests, SVM, gradient boosting, XGBoost/LightGBM/CatBoost, neural networks, and transformers. Evaluated on Titanic (binary) and Iris (multi-class) with cross-validation.</p>

            <p><strong>Results:</strong> SVM achieved 83.2% on Titanic, 93.3% on Iris. Documented performance-interpretability tradeoffs between linear models and deep learning approaches. GPU-optimized training for neural network variants.</p>

            <div class="tech-stack">
                <strong>Tech Stack:</strong>
                <span>scikit-learn, XGBoost, LightGBM, CatBoost, PyTorch, CUDA</span>
            </div>

            <p><a href="https://github.com/Chinmay4285/classification-algorithms-project" target="_blank">View on GitHub →</a></p>
        </div>

    </main>

    <footer>
        <p>All source code and documentation available on GitHub.</p>
    </footer>
</body>
</html>

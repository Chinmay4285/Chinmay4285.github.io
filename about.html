<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About - Chinmay Yalameli</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="experience.html">Experience</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="about.html" class="active">About</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>

    <main>
        <div class="about-header">
            <img src="images/profile.jpg" alt="Chinmay Yalameli" class="profile-photo">
            <div class="about-header-content">
                <h1>About</h1>
                <p>Senior Data Scientist with 6+ years building production ML systems for e-commerce, healthcare, and enterprise analytics. Currently at GAP INC in Seattle, WA.</p>
            </div>
        </div>

        <h2>Background</h2>
        <p>I specialize in recommendation engines, identity resolution systems, and data infrastructure operating at scale. My work focuses on production systems that balance model performance with operational constraints—latency, cost, and interpretability.</p>

        <p>At GAP INC, I lead technical direction for transformer-based recommendation systems serving 40M+ daily users, architect real-time feature infrastructure, and build MLOps systems maintaining 99.9% uptime. These systems have generated $35M+ in measurable revenue impact.</p>

        <h2>Technical Approach</h2>
        <p>Model selection depends on the problem constraints. For high-stakes decisions requiring explainability (healthcare, regulatory domains), I prioritize interpretable models like logistic regression alongside accuracy. For large-scale inference with relaxed interpretability constraints, I use deep learning.</p>

        <p>In production, I optimize for the full system—not just model accuracy. This means considering inference latency, operational cost, monitoring requirements, and graceful degradation under edge cases.</p>

        <h2>Education</h2>
        <div class="education-grid">
            <div class="education-item">
                <h3>University of Washington</h3>
                <p class="education-degree">Master of Science in Information Management</p>
                <p class="education-details">Data Science, Business Intelligence | GPA: 3.96/4.0</p>
                <p class="education-details">2021 - 2022 | Seattle, WA</p>
            </div>

            <div class="education-item">
                <h3>Visvesvaraya Technological University</h3>
                <p class="education-degree">Bachelor of Engineering in Information Science</p>
                <p class="education-details">Valedictorian | GPA: 3.85/4.0</p>
                <p class="education-details">2014 - 2018</p>
            </div>
        </div>

        <h2>Technical Focus Areas</h2>
        <p><strong>Production ML Systems:</strong> Recommendation engines, identity resolution, real-time feature serving, A/B testing infrastructure</p>

        <p><strong>Data Infrastructure:</strong> Terabyte-scale pipelines with PySpark and Azure Databricks, SQL optimization, distributed computing</p>

        <p><strong>MLOps:</strong> Model deployment via Docker/Kubernetes, experiment tracking with MLflow, CI/CD for zero-downtime releases, monitoring and alerting</p>

        <p><strong>Deep Learning:</strong> Transformer architectures (BERT, GPT, T5), recommendation systems, NLP, time series forecasting</p>

        <h2>Current Work</h2>
        <p>Leading technical direction for deep learning recommendation engines using Transformers, XGBoost, and advanced A/B testing. Building real-time vector retrieval systems, terabyte-scale data infrastructure, and MLOps production systems with automated CI/CD pipelines.</p>
    </main>

    <footer>
        <p>Seattle, WA | Open to remote opportunities</p>
    </footer>
</body>
</html>
